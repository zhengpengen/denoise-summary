defaults:
  - _self_

seed: 42

# --- Data Loading ---
loader:
  batch_size: 128
  eval_batch_size: 128
  num_workers: 4
  # Batch size for the one-time dataset preprocessing. Larger is often faster.
  preprocessing_batch_size: 1000
  pin_memory: True

# --- Data Settings ---
data:
  dataset_name: ereverter/cnn_dailymail_extractive
  version: null 
  train: train
  validation: validation
  test: test
  cache_dir: ./cache/cnn_dailymail_extractive/

# --- Model Architecture ---
model:
  # Embedding dimension for sentences and the model's hidden size
  dim: 384
  # Transformer parameters
  num_layers: 6
  num_heads: 6
  dropout: 0.1
  # Dimension of the feedforward network model in nn.TransformerEncoderLayer
  dim_feedforward: 1536 # 4 * dim
  activation: 'gelu'

# --- Task-specific Settings ---
summarization:
  # Model from sentence-transformers to embed sentences
  sentence_embedder_name_or_path: 'all-MiniLM-L6-v2'
  # Output dimension of the sentence embedder. 'all-MiniLM-L6-v2' is 384.
  sentence_embedding_dim: 384
  # Max sentences per document. Documents with more will be truncated.
  max_sentences: 100

# --- Diffusion Process ---
diffusion:
  # Number of noising steps
  timesteps: 1000
  # Noise schedule parameters
  beta_start: 0.0001
  beta_end: 0.02
  beta_schedule: 'linear' # or 'cosine'

# --- Optimizer ---
optim:
  name: 'AdamW'
  weight_decay: 0
  lr: 3e-4
  betas: [0.9, 0.999]
  eps: 1e-8

# --- Trainer Settings ---
trainer:
  accelerator: 'gpu'
  devices: 1
  gradient_clip_val: 1.0
  # Total training steps. Number of epochs will be calculated from this.
  max_steps: 200000
  # Run validation every N training steps
  val_check_interval: 5000
  # Log every N steps
  log_every_n_steps: 50
  # Path to a checkpoint file to resume training from. If null, starts fresh.
  resume_from_checkpoint: null

# --- WandB Logging ---
wandb:
  project: "denoise-summary"
  entity: zhengpengen # Your wandb username or team name
  mode: "online" # "online", "offline", or "disabled"

# --- Hydra Settings ---
hydra:
  run:
    # dir: /content/drive/MyDrive/_ColabOutputs/cnn_dailymail/${now:%Y.%m.%d}/${now:%H%M%S}
    dir: ./outputs/${now:%Y.%m.%d}/${now:%H%M%S}
  job:
    chdir: true
